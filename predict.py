
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# Import from the enhanced modules
try:
    from stock_utils import create_sequences, calculate_metrics
except ImportError:
    # Fallback to original import if enhanced not available
    from stock_utils import create_sequences, calculate_metrics

def predict_future_prices(model, last_sequence, scaler, days=30, model_type='lstm'):
    """
    Predict future stock prices with comprehensive error handling.

    Args:
        model: Trained model (LSTM or Regression)
        last_sequence (np.array): Last sequence of data
        scaler: Data scaler
        days (int): Number of days to predict
        model_type (str): Type of model ('lstm' or 'regression')

    Returns:
        np.array: Predicted prices
    """
    # Input validation
    if last_sequence is None or len(last_sequence) == 0:
        raise ValueError("last_sequence cannot be empty")

    if days <= 0:
        raise ValueError("days must be positive")

    # Check for NaN or infinite values in input sequence
    if np.any(np.isnan(last_sequence)) or np.any(np.isinf(last_sequence)):
        print("‚ö†Ô∏è Warning: Input sequence contains NaN/inf values. Cleaning...")
        last_sequence = np.nan_to_num(last_sequence, nan=0.0, posinf=1.0, neginf=-1.0)

    predictions = []
    current_sequence = last_sequence.copy()

    try:
        for day in range(days):
            if model_type == 'lstm':
                # Reshape for LSTM
                if len(current_sequence.shape) == 1:
                    current_input = current_sequence.reshape((1, current_sequence.shape[0], 1))
                else:
                    current_input = current_sequence.reshape((1, current_sequence.shape[0]))
                    if len(current_input.shape) == 2:
                        current_input = current_input.reshape((current_input.shape[0], current_input.shape[1], 1))

                # Make prediction
                prediction = model.predict(current_input, verbose=0)
                prediction_value = prediction[0, 0] if len(prediction.shape) > 1 else prediction[0]

                # Validate prediction
                if np.isnan(prediction_value) or np.isinf(prediction_value):
                    print(f"‚ö†Ô∏è Warning: NaN/inf prediction at day {day+1}, using last valid value")
                    if len(predictions) > 0:
                        prediction_value = predictions[-1]
                    else:
                        prediction_value = current_sequence[-1] if len(current_sequence) > 0 else 0.0

                predictions.append(prediction_value)

                # Update sequence for next prediction
                current_sequence = np.append(current_sequence[1:], prediction_value)

            else:
                # For regression models
                if len(current_sequence.shape) == 1:
                    current_input = current_sequence.reshape(1, -1)
                else:
                    current_input = current_sequence

                # Make prediction
                prediction = model.predict(current_input, verbose=0)
                prediction_value = prediction[0] if hasattr(prediction, '__len__') else prediction

                # Validate prediction
                if np.isnan(prediction_value) or np.isinf(prediction_value):
                    print(f"‚ö†Ô∏è Warning: NaN/inf prediction at day {day+1}, using fallback")
                    if len(predictions) > 0:
                        prediction_value = predictions[-1] * 1.001  # Small increment
                    else:
                        prediction_value = current_sequence[-1] if len(current_sequence) > 0 else 100.0

                predictions.append(prediction_value)

                # For regression, we don't update the sequence in the same way
                # Instead, we might use a sliding window approach
                if len(current_sequence) > 1:
                    current_sequence = np.append(current_sequence[1:], prediction_value)

        # Convert predictions to numpy array
        predictions = np.array(predictions)

        # Inverse transform predictions if scaler provided
        if scaler is not None:
            try:
                predictions_reshaped = predictions.reshape(-1, 1)
                predictions = scaler.inverse_transform(predictions_reshaped).flatten()

                # Final validation after inverse transform
                if np.any(np.isnan(predictions)) or np.any(np.isinf(predictions)):
                    print("‚ö†Ô∏è Warning: NaN/inf after inverse transform, cleaning...")
                    predictions = np.nan_to_num(predictions, nan=100.0, posinf=1000.0, neginf=10.0)

            except Exception as e:
                print(f"‚ö†Ô∏è Warning: Error in inverse transform: {e}, using raw predictions")

        print(f"‚úÖ Successfully generated {len(predictions)} price predictions")
        return predictions

    except Exception as e:
        print(f"‚ùå Error in predict_future_prices: {e}")
        # Return fallback predictions
        print("üîß Using fallback prediction strategy...")
        if len(predictions) > 0:
            # Use trend from existing predictions
            last_pred = predictions[-1]
            remaining_days = days - len(predictions)
            trend = 0.001  # Small upward trend
            fallback_preds = [last_pred * (1 + trend * i) for i in range(1, remaining_days + 1)]
            return np.array(predictions + fallback_preds)
        else:
            # Generate simple trend-based predictions
            base_value = last_sequence[-1] if len(last_sequence) > 0 else 100.0
            trend_predictions = [base_value * (1 + 0.001 * i) for i in range(1, days + 1)]
            return np.array(trend_predictions)

def create_prediction_dates(start_date, num_days):
    """
    Create dates for predictions, skipping weekends.

    Args:
        start_date (datetime): Starting date
        num_days (int): Number of days to predict

    Returns:
        list: List of dates
    """
    if not isinstance(start_date, (datetime, pd.Timestamp)):
        raise ValueError("start_date must be a datetime object")

    if num_days <= 0:
        raise ValueError("num_days must be positive")

    dates = []
    current_date = start_date
    days_added = 0

    # Safety counter to prevent infinite loops
    safety_counter = 0
    max_iterations = num_days * 3  # Allow for weekends

    while days_added < num_days and safety_counter < max_iterations:
        # Skip weekends (Saturday=5, Sunday=6)
        if current_date.weekday() < 5:  # Monday=0 to Friday=4
            dates.append(current_date)
            days_added += 1

        current_date += timedelta(days=1)
        safety_counter += 1

    if len(dates) < num_days:
        print(f"‚ö†Ô∏è Warning: Only generated {len(dates)} dates instead of {num_days}")

    return dates

def evaluate_model(model, X_test, y_test, scaler, model_type='lstm'):
    """
    Evaluate model performance on test data with comprehensive error handling.

    Args:
        model: Trained model
        X_test (np.array): Test features
        y_test (np.array): Test targets
        scaler: Data scaler
        model_type (str): Type of model

    Returns:
        tuple: (predictions, metrics)
    """
    if model is None:
        raise ValueError("Model cannot be None")

    if len(X_test) == 0 or len(y_test) == 0:
        raise ValueError("Test data cannot be empty")

    # Input validation
    if np.any(np.isnan(X_test)) or np.any(np.isnan(y_test)):
        print("‚ö†Ô∏è Warning: Test data contains NaN values")
        # Remove NaN samples
        valid_mask = ~(np.any(np.isnan(X_test), axis=1) | np.isnan(y_test))
        X_test = X_test[valid_mask]
        y_test = y_test[valid_mask]
        print(f"Removed {(~valid_mask).sum()} samples with NaN values")

    if len(X_test) == 0:
        raise ValueError("No valid test samples remain after NaN removal")

    try:
        if model_type == 'lstm':
            # Reshape for LSTM
            if len(X_test.shape) == 2:
                X_test_reshaped = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))
            else:
                X_test_reshaped = X_test

            predictions = model.predict(X_test_reshaped, verbose=0)

        else:
            predictions = model.predict(X_test, verbose=0)

        # Validate predictions
        if np.any(np.isnan(predictions)):
            print("‚ö†Ô∏è Warning: Model produced NaN predictions")
            predictions = np.nan_to_num(predictions, nan=0.0)

        # Reshape predictions if needed
        if len(predictions.shape) > 1:
            predictions = predictions.flatten()

        # Inverse transform predictions and actual values
        if scaler is not None:
            try:
                predictions_scaled = scaler.inverse_transform(predictions.reshape(-1, 1)).flatten()
                y_test_scaled = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()
            except Exception as e:
                print(f"‚ö†Ô∏è Warning: Error in inverse scaling: {e}, using raw values")
                predictions_scaled = predictions
                y_test_scaled = y_test
        else:
            predictions_scaled = predictions
            y_test_scaled = y_test

        # Calculate metrics
        metrics = calculate_metrics(y_test_scaled, predictions_scaled)

        print(f"‚úÖ Model evaluation completed on {len(predictions_scaled)} samples")
        return predictions_scaled, metrics

    except Exception as e:
        print(f"‚ùå Error in model evaluation: {e}")
        # Return fallback values
        fallback_predictions = np.full(len(y_test), np.mean(y_test))
        fallback_metrics = {
            'MSE': np.nan,
            'RMSE': np.nan,
            'MAE': np.nan,
            'R2': 0.0
        }
        return fallback_predictions, fallback_metrics

def create_prediction_dataframe(historical_data, predictions, prediction_dates):
    """
    Create a dataframe combining historical and predicted data with error handling.

    Args:
        historical_data (pd.DataFrame): Historical stock data
        predictions (np.array): Predicted values
        prediction_dates (list): Dates for predictions

    Returns:
        pd.DataFrame: Combined dataframe
    """
    try:
        # Validate inputs
        if historical_data is None or len(historical_data) == 0:
            raise ValueError("Historical data cannot be empty")

        if len(predictions) == 0:
            raise ValueError("Predictions cannot be empty")

        if len(predictions) != len(prediction_dates):
            print(f"‚ö†Ô∏è Warning: Predictions length ({len(predictions)}) != dates length ({len(prediction_dates)})")
            min_len = min(len(predictions), len(prediction_dates))
            predictions = predictions[:min_len]
            prediction_dates = prediction_dates[:min_len]

        # Clean predictions
        predictions = np.nan_to_num(predictions, nan=100.0)

        # Create prediction dataframe
        pred_df = pd.DataFrame({
            'Date': prediction_dates,
            'Predicted_Close': predictions,
            'Type': 'Predicted'
        })

        # Prepare historical data
        hist_cols = ['Date', 'Close'] if 'Close' in historical_data.columns else ['Date'] + [c for c in historical_data.columns if 'close' in c.lower()][:1]

        if len(hist_cols) < 2:
            print("‚ö†Ô∏è Warning: Cannot find Close price column in historical data")
            return pred_df

        hist_subset = historical_data[hist_cols].copy()
        hist_subset.columns = ['Date', 'Predicted_Close']
        hist_subset['Type'] = 'Historical'

        # Combine dataframes
        combined_df = pd.concat([hist_subset, pred_df], ignore_index=True)

        print(f"‚úÖ Created combined dataframe with {len(combined_df)} rows")
        return combined_df

    except Exception as e:
        print(f"‚ùå Error creating prediction dataframe: {e}")
        # Return minimal dataframe
        return pd.DataFrame({
            'Date': prediction_dates,
            'Predicted_Close': np.nan_to_num(predictions, nan=100.0),
            'Type': 'Predicted'
        })

def generate_trading_signals(predictions, current_price, threshold=0.02):
    """
    Generate trading signals based on predictions with enhanced validation.

    Args:
        predictions (np.array): Predicted prices
        current_price (float): Current stock price
        threshold (float): Percentage threshold for signals

    Returns:
        dict: Trading signals and analysis
    """
    try:
        # Input validation
        if len(predictions) == 0:
            raise ValueError("Predictions cannot be empty")

        if current_price <= 0:
            print("‚ö†Ô∏è Warning: Invalid current price, using fallback")
            current_price = np.mean(predictions) if len(predictions) > 0 else 100.0

        # Clean predictions
        predictions = np.nan_to_num(predictions, nan=current_price)
        predictions = predictions[np.isfinite(predictions)]

        if len(predictions) == 0:
            print("‚ö†Ô∏è Warning: No valid predictions for signal generation")
            return {
                'signal': 'HOLD',
                'confidence': 50.0,
                'current_price': current_price,
                'predicted_price': current_price,
                'price_change_percent': 0.0,
                'max_predicted': current_price,
                'min_predicted': current_price,
                'avg_predicted': current_price,
                'volatility': 0.0
            }

        # Calculate metrics
        final_prediction = predictions[-1]
        price_change = (final_prediction - current_price) / current_price if current_price != 0 else 0

        # Generate signal
        if price_change > threshold:
            signal = 'BUY'
            confidence = min(abs(price_change) / threshold * 50, 100.0)
        elif price_change < -threshold:
            signal = 'SELL'
            confidence = min(abs(price_change) / threshold * 50, 100.0)
        else:
            signal = 'HOLD'
            confidence = 50.0 - abs(price_change) / threshold * 25

        # Calculate additional metrics
        max_price = np.max(predictions)
        min_price = np.min(predictions)
        avg_price = np.mean(predictions)
        volatility = np.std(predictions) if len(predictions) > 1 else 0.0

        result = {
            'signal': signal,
            'confidence': max(0.0, min(100.0, confidence)),
            'current_price': current_price,
            'predicted_price': final_prediction,
            'price_change_percent': price_change * 100,
            'max_predicted': max_price,
            'min_predicted': min_price,
            'avg_predicted': avg_price,
            'volatility': volatility
        }

        print(f"‚úÖ Generated trading signal: {signal} (confidence: {confidence:.1f}%)")
        return result

    except Exception as e:
        print(f"‚ùå Error generating trading signals: {e}")
        # Return safe default signal
        return {
            'signal': 'HOLD',
            'confidence': 50.0,
            'current_price': current_price if current_price > 0 else 100.0,
            'predicted_price': current_price if current_price > 0 else 100.0,
            'price_change_percent': 0.0,
            'max_predicted': current_price if current_price > 0 else 100.0,
            'min_predicted': current_price if current_price > 0 else 100.0,
            'avg_predicted': current_price if current_price > 0 else 100.0,
            'volatility': 0.0
        }

def backtest_predictions(model, data, lookback_days, prediction_days, scaler, model_type='lstm'):
    """
    Backtest model predictions on historical data with comprehensive error handling.

    Args:
        model: Trained model
        data (pd.DataFrame): Historical data
        lookback_days (int): Days to look back
        prediction_days (int): Days to predict forward
        scaler: Data scaler
        model_type (str): Model type

    Returns:
        pd.DataFrame: Backtest results
    """
    results = []

    try:
        if len(data) < lookback_days + prediction_days:
            print("‚ö†Ô∏è Warning: Insufficient data for backtesting")
            return pd.DataFrame(columns=['start_date', 'end_date', 'mae', 'mape', 'predicted_trend', 'actual_trend'])

        # Use last 30% of data for backtesting (more conservative)
        test_start_idx = max(lookback_days, int(len(data) * 0.7))
        test_end_idx = len(data) - prediction_days

        if test_start_idx >= test_end_idx:
            print("‚ö†Ô∏è Warning: Not enough data for backtesting after reserving prediction window")
            return pd.DataFrame(columns=['start_date', 'end_date', 'mae', 'mape', 'predicted_trend', 'actual_trend'])

        backtest_points = min(10, (test_end_idx - test_start_idx) // prediction_days)  # Limit backtest points

        for i in range(backtest_points):
            idx = test_start_idx + i * prediction_days

            if idx + prediction_days > len(data):
                break

            try:
                # Get sequence for prediction
                if 'Close' not in data.columns:
                    print("‚ö†Ô∏è Warning: 'Close' column not found in data")
                    continue

                sequence = data['Close'].iloc[idx - lookback_days:idx].values

                # Validate sequence
                if len(sequence) < lookback_days or np.any(np.isnan(sequence)):
                    print(f"‚ö†Ô∏è Skipping backtest point {i} due to invalid sequence")
                    continue

                # Scale sequence
                if scaler is not None:
                    try:
                        scaled_sequence = scaler.transform(sequence.reshape(-1, 1)).flatten()
                    except:
                        scaled_sequence = sequence
                else:
                    scaled_sequence = sequence

                # Make predictions
                predictions = predict_future_prices(
                    model, scaled_sequence, scaler,
                    days=prediction_days, model_type=model_type
                )

                # Get actual values
                actual_values = data['Close'].iloc[idx:idx + prediction_days].values

                # Validate actual values
                if len(actual_values) != len(predictions) or np.any(np.isnan(actual_values)):
                    print(f"‚ö†Ô∏è Skipping backtest point {i} due to invalid actual values")
                    continue

                # Calculate metrics
                mae = np.mean(np.abs(predictions - actual_values))
                mape = np.mean(np.abs((predictions - actual_values) / actual_values)) * 100

                # Determine trends
                pred_trend = 'up' if predictions[-1] > predictions[0] else 'down'
                actual_trend = 'up' if actual_values[-1] > actual_values[0] else 'down'

                # Get dates safely
                try:
                    start_date = data['Date'].iloc[idx] if 'Date' in data.columns else f"Day_{idx}"
                    end_date = data['Date'].iloc[idx + prediction_days - 1] if 'Date' in data.columns else f"Day_{idx + prediction_days - 1}"
                except:
                    start_date = f"Day_{idx}"
                    end_date = f"Day_{idx + prediction_days - 1}"

                results.append({
                    'start_date': start_date,
                    'end_date': end_date,
                    'mae': mae,
                    'mape': min(mape, 1000.0),  # Cap MAPE at 1000%
                    'predicted_trend': pred_trend,
                    'actual_trend': actual_trend
                })

            except Exception as e:
                print(f"‚ö†Ô∏è Error in backtest iteration {i}: {e}")
                continue

        backtest_df = pd.DataFrame(results)

        if len(backtest_df) == 0:
            print("‚ö†Ô∏è Warning: No successful backtest results")
            return pd.DataFrame(columns=['start_date', 'end_date', 'mae', 'mape', 'predicted_trend', 'actual_trend'])

        print(f"‚úÖ Completed backtesting with {len(backtest_df)} results")
        return backtest_df

    except Exception as e:
        print(f"‚ùå Error in backtesting: {e}")
        return pd.DataFrame(columns=['start_date', 'end_date', 'mae', 'mape', 'predicted_trend', 'actual_trend'])